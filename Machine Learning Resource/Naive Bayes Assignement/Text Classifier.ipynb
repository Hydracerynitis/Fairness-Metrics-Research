{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPSCI 361 Assignment 2 by Kejun Dai\n",
    "\n",
    "## **Part 1** : Report\n",
    "\n",
    "### **Part 1.1**: Problem motivation and Evaluation Method\n",
    "\n",
    "The machine learning problem for this challenge is given a paragraph of an abstract of a protein, the model needs to be able to predict the whether the protein fall into category of Archaea, Bacteria, Eukaryota, or Virus. To solve the problem. I plan to use Naive Bayes algorithm to train a classifier. \n",
    "\n",
    "In this experiment, I will randomly split the entries in the data set into training sets and testing set beforehand. Traning set is roughly 70% of original data sets and testing set is roughly 30% of original data sets. Entry in training sets will only be used to train models and Entry in testing sets will only be used to test models. I will use Bootstrap to sample the traing data and testing data from traing set and testing set respectively\n",
    "\n",
    "In order to test and evaluate my Naive Bayes algorithm, I plan to first run a ten-fold cross validation on the algorithm, calculating its average training accuracy. After that I put the model against testing with 20 randomly bootstrapped data sets to get its average testing accuracy. To compare two iterations of my Naive Bayes algorithm I will use t-test with `ttest_ind` from `scipy.stats` library to evaluate the statistical difference. I will accept an iteration of Naive Bayes algorithm performs better than its predecessor only if its average testing accuracy is greater and it's statistical different at 95% confident level.\n",
    "\n",
    "### **Part 1.2.1**: Standard Naive Bayes Algorithm\n",
    "\n",
    "My first Naive Bayes algorithm is to implement the standard Naive Bayes outlined in the Mitchell's \"Machine Learning\". \n",
    "\n",
    "In this algorithm, each abstract is regarded as a combination of occurances of different identically distributied words. These words are assumed to have the equal likelihood to appear in an abstract. The classes are represented by \"A\", \"B\",\"E\" ,\"V\" repectively, and I use `[{class of A},{class of B},{class of E},{class of V}]` through out my algorithm to represent the same values that is related with each classes respectively.\n",
    "\n",
    "The implementation will consist of three parts,`word_weight`,`label_prob` and `total_word_count`. `word_weight` is a dictionary that record the numbers of occurence of each word in abstract with different classes. `label_prob` is a array that records the prior likelihood of the abstract being certain class. `total_word_count` is a array that record the total number of occurances of words in abstracts with different classes\n",
    "\n",
    "To train such model, the algorithm will for each entry identify the class of the abstract and increment the number of occurences of said class. It then reads through the abstract. For each occurence of word it increments the total number of occurances of words in entry's class and the number of occucurance of said word in entry class. After reading through all entries, the algorithm will calculate the prior likelihood of the abstract being certain class in log space according number of occurences of classes. It produces the model with all these informations.\n",
    "\n",
    "When predicting the class of a given abstract, the model will first set their current predicted likelihood of each class to be the values in `label_prob` before reading through the abstract. For each word in the abstract, the model will calculatethe likelihood of occurence of these words given certain class with laplace smoothing in log space and increment them to the current predicted likelihood of said class. After reading the abstract, the model will choose one of classes with the greatest likelihood to be its prediction\n",
    "\n",
    "### **Part 1.2.2**: Standard Naive Bayes Algorithm with oversampling minority classes\n",
    "\n",
    "After running some test on my first Naive Bayes algorithm, I have noticed that its accuracy to predict abstracts that are Archaea or Virus abyssmal compared to predict abstracts that are Bacteria and Eukaryota (38% and 0% compared to 93% and 99%). And after analysing the training datas, I found that the data set is heavily unbalanced with majority classes Bacteria and Eukaryota take 94% of the data, while the minority classes Archaea or Virus take 6% of the data.\n",
    "\n",
    "So I use `RandomOverSampler` from the library `imblearn.over_sampling`to oversample the minority classes so that both majority classes and minority classes take 50% of the training data before I use them to train my standard Naive Bayes Algorithm.\n",
    "\n",
    "### **Part 1.2.3**: Complement Naive Bayes Algorithm with oversampling minority classes\n",
    "\n",
    "In Rennie at al.(2003) \"Tackling the Poor Assumptions of Naive Bayes Text Classifiers\", the article idetifies the problems of the Naive Bayes Classifer on documentation problem. One of them is that the classifer will make tilted prediction even when the classes in the training data is a little bit imbalanced. The article propose Complement Naive Bayes Algorithm where it use likelihood of occurance of word in abstracts that is not the class to calculate its prediction.\n",
    "\n",
    "Since my model's accuracy to predict abstracts that are Archaea or Virus is still much poorer than the accuracy to predict abstracts that are Bacteria and Eukaryota even after employing oversampling minority classes (48% and 76% compared to 92% and 99%). I need a way to reduce the Variance of my model in predicting abstracts that are Archaea or Virus due to oversampling almost 20 times size of the orignial data. So on atop of that I modify my standard Naive Bayes algorithm to be an implementation of Complement Naive Bayes algorithm in Rennie at al.(2003). For each word the model read in the abstract, the model will deduct the likelihood of the occurance of the word in abstracts of other classes from the predicited likelihood of classes now\n",
    "\n",
    "### **Part 1.3**: The result and the final chosen model\n",
    "\n",
    "In this section, I will use acronym *SNB* to describe Standard Naive Bayes (Part 1.2.1), *SNBwOM* to describe Standard Naive Bayes with Oversampling Minority classes (Part 1.2.2) and *CNBwOM* to describe Complemtary Naive Bayes with Oversampling Minority Classes (Part 1.2.3).\n",
    "\n",
    "The reuslt of the models is in the following:\n",
    "| Models | Average Training Accuracy | Average Testing Accuracy |\n",
    "| --- | --- | --- |\n",
    "| *SNB* | 95.56% | 91.88% |\n",
    "| *SNBwOM* | 98.81% | 93.53% |\n",
    "| *CNBwOM* | 98.45% | 95.31% |\n",
    "\n",
    "It can be seen that *SNBwOM* brings great improvements on the *SNB* models where both average training accuracy and average testing accuracy has increased compared to SNB. *CNBwOM* offers an improvement of Variance on *SNBwOM* where it increase the average Testing accuracy with a tiny bit drop off from the average training accuracy. And at 95% confident level, testing accuracy of *SNBwOM* is statistically different with testing accuracy of *SNB* and testing accuracy of *CNBwOM* is statisitcally different with testing accuracy of *SNBwOM* and testing accuracy of *SNB*. We can say *CNBwOM* performs the best among three models while *SMBwOM* also performs better than *SNB*\n",
    "\n",
    "In conclusion, *CNBwOM* will be the model I use to tackle the challenge.\n",
    "\n",
    "---\n",
    "\n",
    "## **Part 2** : Code Implementation\n",
    "\n",
    "### **Part 2.1**: Implement a standard version of Naive Bayes algorithm on the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T04:29:11.543513100Z",
     "start_time": "2023-09-25T04:29:00.370240300Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from random import *\n",
    "import pandas as pd\n",
    "import math\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4000 examples in the original dataset\n",
      "There are 2808 examples in the training set\n",
      "There are 1192 examples in the testing set\n"
     ]
    }
   ],
   "source": [
    "#Classes for the  abstract\n",
    "possible_label=[\"A\",\"B\",\"E\",\"V\"]\n",
    "\n",
    "#Reading training examples from the file\n",
    "dataset=[]\n",
    "file=open(\"trg.csv\")\n",
    "data_csv=csv.DictReader(file)\n",
    "for row in data_csv:\n",
    "   dataset.append([row[\"abstract\"],row[\"class\"]])\n",
    "file.close()\n",
    "print(f\"There are {len(dataset)} examples in the original dataset\")\n",
    "\n",
    "#Spliting examples into training set and testing set randomly\n",
    "testset=[]\n",
    "trainset=[]\n",
    "seed(100)\n",
    "for i in dataset:\n",
    "    if random()<=0.3:\n",
    "        testset.append(i)\n",
    "    else:\n",
    "        trainset.append(i)\n",
    "print(f\"There are {len(trainset)} examples in the training set\")\n",
    "print(f\"There are {len(testset)} examples in the testing set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has the following classes distribution:\n",
      "                   A       B        E      V\n",
      "counts         85.00  1122.0  1508.00  93.00\n",
      "distributions   0.03     0.4     0.54   0.03\n",
      "\n",
      "The training set has the following classes distribution:\n",
      "                   A      B       E      V\n",
      "counts         43.00  480.0  636.00  33.00\n",
      "distributions   0.04    0.4    0.53   0.03\n"
     ]
    }
   ],
   "source": [
    "#Helper method to extract class distribution of a dataset\n",
    "def analyze_label_distribution(dataset):\n",
    "    label_count=[0,0,0,0]\n",
    "    for d in dataset:\n",
    "        label_count[possible_label.index(d[1])]+=1\n",
    "    print(pd.DataFrame([label_count,[round(x/sum(label_count),2) for x in label_count]],columns=possible_label,index=[\"counts\",\"distributions\"]))\n",
    "\n",
    "print(\"The training set has the following classes distribution:\")\n",
    "analyze_label_distribution(trainset)\n",
    "print(\"\\nThe training set has the following classes distribution:\")\n",
    "analyze_label_distribution(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Standard Naive Bayesian model\n",
    "class BayseianModel:\n",
    "    def __init__(self,word_weight,label_prob,total_word_count) -> None:\n",
    "        self.__word_weight=word_weight\n",
    "        self.__label_prob=label_prob\n",
    "        self.__total_word_count=total_word_count\n",
    "    \n",
    "    @property\n",
    "    def word_weight(self):\n",
    "        return self.__word_weight\n",
    "    \n",
    "    @property\n",
    "    def label_prob(self):\n",
    "        return self.__label_prob\n",
    "    \n",
    "    @property\n",
    "    def total_word_count(self):\n",
    "        return self.__total_word_count\n",
    "\n",
    "    def predict(self,abstract:str):\n",
    "        word_amount=len(self.word_weight)\n",
    "        word_list=abstract.split()\n",
    "        propbability=list(self.label_prob)\n",
    "        for w in word_list:\n",
    "            if w in self.word_weight:\n",
    "                index=0\n",
    "                while index<4:\n",
    "                    smooth_prob=(self.word_weight[w][index]+1)/(self.total_word_count[index]+word_amount)\n",
    "                    propbability[index]+=math.log(smooth_prob)\n",
    "                    index+=1\n",
    "        max_index=[index for index,item in enumerate(propbability) if item==max(propbability)]\n",
    "        return possible_label[choice(max_index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to train a Standard Naive Bayes Model from a dataset\n",
    "def train_naive_Bayesian(dataset):\n",
    "    word_dict=dict()\n",
    "    total_count=[0,0,0,0]\n",
    "    label_count=[0,0,0,0]\n",
    "    for D in dataset:\n",
    "        analyze_abstract(word_dict,total_count,D[0],D[1])\n",
    "        label_count[possible_label.index(D[1])]+=1\n",
    "    return BayseianModel(word_dict,[math.log(x/len(dataset)) if x!=0 else 0 for x in label_count],total_count)\n",
    "\n",
    "def analyze_abstract(word_dict,total_count,abstract:str, label):\n",
    "    word_list=abstract.split()\n",
    "    label_index=possible_label.index(label)\n",
    "    total_count[label_index]+=len(word_list)\n",
    "    for word in word_list:\n",
    "        if word not in word_dict:\n",
    "            word_dict[word]=[0,0,0,0]\n",
    "        word_dict[word][label_index]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put the Naive Bayes Model to test against a dataset. Output the number of correct guess, the number of incorrect guess and the accuracy\n",
    "def evaluate(bayesian_model, testset):\n",
    "    success=0\n",
    "    fail=0\n",
    "    for D in testset:\n",
    "        if(bayesian_model.predict(D[0])==D[1]):\n",
    "            success+=1\n",
    "        else:\n",
    "            fail+=1\n",
    "    accuracy=success/(success+fail)\n",
    "    return success,fail,accuracy\n",
    "#Put the Naive Bayes Model to test against a randomly bootstrap dataset several times. Output the list of accuracy for analyse\n",
    "def get_test_accuracy_model(model,times):\n",
    "    accuracy_list=[]\n",
    "    for i in range(times):\n",
    "        test_data=[]\n",
    "        while len(test_data)<800:\n",
    "            test_data.append(choice(testset))\n",
    "        accuracy_list.append(evaluate(model,test_data)[2])\n",
    "    return accuracy_list\n",
    "#Execute a ten fold cross validation on a Naive Bayes, output the list of validation accuracy for analysis\n",
    "def ten_fold_cross_validate_NB(data):\n",
    "    folds=[[],[],[],[],[],[],[],[],[],[]]\n",
    "    data=list(data)\n",
    "    while len(data)>0:\n",
    "        fold_slot=list(range(10))\n",
    "        while len(fold_slot)>0 and len(data)!=0:\n",
    "            example=data.pop(randint(0,len(data)-1))\n",
    "            slot=fold_slot.pop(randint(0,len(fold_slot)-1))\n",
    "            folds[slot].append(example)\n",
    "    accuracy_list=[]\n",
    "    for i in range(10):\n",
    "        valid_fold=folds[i]\n",
    "        train_fold=[]\n",
    "        for f in folds:\n",
    "            if f!=valid_fold:\n",
    "                train_fold+=f\n",
    "        model=train_naive_Bayesian(train_fold)\n",
    "        evaluation=evaluate(model,valid_fold)\n",
    "        accuracy_list.append(evaluation[2])\n",
    "    return accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the ten fold cross validation is:\n",
      "[0.9625, 0.95, 0.95625, 0.94375, 0.98125, 0.9625, 0.94375, 0.93125, 0.9875, 0.9375]\n",
      "The average training error is 0.9556250000000001\n",
      "\n",
      "There are 736 cases of correct prediction and 64 cases of incorrect prediction. The accuray of the Naive Bayesian model is 0.92\n",
      "\n",
      "The result of 20 test with random dataset of the model is as follows:\n",
      "[0.91375, 0.90875, 0.93375, 0.91375, 0.89875, 0.915, 0.93, 0.92375, 0.905, 0.94125, 0.9125, 0.91125, 0.915, 0.925, 0.92, 0.9375, 0.92125, 0.90875, 0.9025, 0.93875]\n",
      "The accuracy of standard Naive Bayesian modle is 0.9188124999999999\n"
     ]
    }
   ],
   "source": [
    "#Bootstrap a training data set\n",
    "train_data=[]\n",
    "while len(train_data)<1600:\n",
    "    train_data.append(choice(trainset))\n",
    "\n",
    "ten_fold_accuracy_NB=ten_fold_cross_validate_NB(train_data)\n",
    "print(\"The result of the ten fold cross validation is:\")\n",
    "print(ten_fold_accuracy_NB)\n",
    "print(f\"The average training error is {sum(ten_fold_accuracy_NB)/10}\\n\")\n",
    "\n",
    "#Use the bootstrap training set to train a standard Naive Bayes \n",
    "bayesian_model=train_naive_Bayesian(train_data)\n",
    "#Bootstrap a testing set\n",
    "test_data=[]\n",
    "while len(test_data)<800:\n",
    "    test_data.append(choice(testset))\n",
    "\n",
    "success,fail,accuracy=evaluate(bayesian_model,test_data)\n",
    "print(f\"There are {success} cases of correct prediction and {fail} cases of incorrect prediction. The accuray of the Naive Bayesian model is {accuracy}\\n\")\n",
    "\n",
    "standard_Bayesian=get_test_accuracy_model(bayesian_model,20)\n",
    "print(\"The result of 20 test with random dataset of the model is as follows:\")\n",
    "print(standard_Bayesian)\n",
    "print(f\"The accuracy of standard Naive Bayesian modle is {sum(standard_Bayesian)/20}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Part 2.2**: Oversampling Minority class to deal with imbalance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put the Naive Bayes Model to test against a dataset. Output the number of correct guess, the number of incorrect guess and the accuracy for each classes of examples\n",
    "def detail_evaluation(bayesian_model, testset):\n",
    "    success=[0,0,0,0]\n",
    "    fail=[0,0,0,0]\n",
    "    for D in testset:\n",
    "        if(bayesian_model.predict(D[0])==D[1]):\n",
    "            success[possible_label.index(D[1])]+=1\n",
    "        else:\n",
    "            fail[possible_label.index(D[1])]+=1\n",
    "    accuracy=[round(success[i]/(success[i]+fail[i]),2) for i in range(4)]\n",
    "    total_accuracy=sum(success)/(sum(success)+sum(fail))\n",
    "    return success,fail,accuracy,total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bootstarp training data set has the following classes distribution:\n",
      "                   A      B       E      V\n",
      "counts         40.00  640.0  872.00  48.00\n",
      "distributions   0.03    0.4    0.55   0.03\n",
      "\n",
      "The accuray of the Naive Bayesian model is 0.92\n",
      "the number of correct guess, the number of incorrect guess and the accuracy for each classes of examples is in the following:\n",
      "              A       B       E     V\n",
      "success    8.00  328.00  400.00   0.0\n",
      "fail      13.00   24.00    6.00  21.0\n",
      "accuracy   0.38    0.93    0.99   0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"The bootstarp training data set has the following classes distribution:\")\n",
    "analyze_label_distribution(train_data)\n",
    "success,fail,accuracy,total_accuracy=detail_evaluation(bayesian_model,test_data)\n",
    "print(f\"\\nThe accuray of the Naive Bayesian model is {total_accuracy}\")\n",
    "print(\"the number of correct guess, the number of incorrect guess and the accuracy for each classes of examples is in the following:\")\n",
    "print(pd.DataFrame([success,fail,accuracy],index=[\"success\",\"fail\",\"accuracy\"],columns=possible_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution of classes of examples in the training data set is:\n",
      "                   A      B       E      V\n",
      "counts         40.00  640.0  872.00  48.00\n",
      "distributions   0.03    0.4    0.55   0.03\n",
      "\n",
      "The distribution of classes of examples in the training data set is:\n",
      "                    A       B       E       V\n",
      "counts         756.00  640.00  872.00  756.00\n",
      "distributions    0.25    0.21    0.29    0.25\n",
      "\n",
      "The result of the ten fold cross validation is:\n",
      "[0.9768211920529801, 0.9933774834437086, 0.9933774834437086, 0.9933993399339934, 0.9834437086092715, 0.9966887417218543, 0.9966996699669967, 0.9602649006622517, 0.9900990099009901, 0.9966996699669967]\n",
      "The average training error is 0.9880871199702753\n",
      "\n",
      "The accuray of the Naive Bayesian model is 0.93875\n",
      "the number of correct guess, the number of incorrect guess and the accuracy for each classes of examples is in the following:\n",
      "              A       B       E      V\n",
      "success   10.00  325.00  400.00  16.00\n",
      "fail      11.00   27.00    6.00   5.00\n",
      "accuracy   0.48    0.92    0.99   0.76\n",
      "\n",
      "The result of 20 test with random dataset of the model is as follows:\n",
      "[0.93625, 0.94125, 0.93, 0.92125, 0.92375, 0.93875, 0.935, 0.9375, 0.92375, 0.92875, 0.94375, 0.95375, 0.93375, 0.93125, 0.93875, 0.94625, 0.94875, 0.92875, 0.9325, 0.93125]\n",
      "The accuracy of standard Naive Bayesian modle with oversampled minority class is 0.9352500000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"The distribution of classes of examples in the training data set is:\")\n",
    "analyze_label_distribution(train_data)\n",
    "# Oversample Minority class \n",
    "majority=len([d for d in train_data if d[1]==\"B\" or d[1]==\"E\"])\n",
    "oversample_minority=math.floor(majority/2)\n",
    "ros=RandomOverSampler(random_state=100, sampling_strategy={\"A\":oversample_minority,\"V\":oversample_minority})\n",
    "train_data=ros.fit_resample(train_data,[d[1] for d in train_data])[0]\n",
    "print(\"\\nThe distribution of classes of examples in the training data set is:\")\n",
    "analyze_label_distribution(train_data)\n",
    "\n",
    "ten_fold_accuracy_NB=ten_fold_cross_validate_NB(train_data)\n",
    "print(\"\\nThe result of the ten fold cross validation is:\")\n",
    "print(ten_fold_accuracy_NB)\n",
    "print(f\"The average training error is {sum(ten_fold_accuracy_NB)/10}\\n\")\n",
    "\n",
    "# Train the Standard Naive Bayes again with the oversampled training data\n",
    "bayesian_model_oversample=train_naive_Bayesian(train_data)\n",
    "\n",
    "success,fail,accuracy,total_accuracy=detail_evaluation(bayesian_model_oversample,test_data)\n",
    "print(f\"The accuray of the Naive Bayesian model is {total_accuracy}\")\n",
    "print(\"the number of correct guess, the number of incorrect guess and the accuracy for each classes of examples is in the following:\")\n",
    "print(pd.DataFrame([success,fail,accuracy],index=[\"success\",\"fail\",\"accuracy\"],columns=possible_label))\n",
    "\n",
    "oversample_Bayesian=get_test_accuracy_model(bayesian_model_oversample,20)\n",
    "print(\"\\nThe result of 20 test with random dataset of the model is as follows:\")\n",
    "print(oversample_Bayesian)\n",
    "print(f\"The accuracy of standard Naive Bayesian modle with oversampled minority class is {sum(oversample_Bayesian)/20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Least 91% confident level, there is a statistical significant difference between the accuracy of standard Naive Bayes algorithm\n",
      "and standard Naive Bayes algorithem with oversample minority class on the test dataset\n"
     ]
    }
   ],
   "source": [
    "stats,pvalue =ttest_ind(standard_Bayesian,oversample_Bayesian)\n",
    "siglvl=math.ceil(100-abs(stats*2))\n",
    "print(f\"At Least {siglvl}% confident level, there is a statistical significant difference between the accuracy of standard Naive Bayes algorithm\")\n",
    "print(\"and standard Naive Bayes algorithem with oversample minority class on the test dataset\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Part 2.2**: Switch to Complement Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complement Naive Bayes algorithem, modified from the standard Naive Bayes algorithm from Part 1\n",
    "class ComplementBayesainModel():\n",
    "    def __init__(self,word_weight,label_prob,total_word_count) -> None:\n",
    "        self.__word_weight=word_weight\n",
    "        self.__label_prob=label_prob\n",
    "        self.__total_word_count=total_word_count\n",
    "    \n",
    "    @property\n",
    "    def word_weight(self):\n",
    "        return self.__word_weight\n",
    "    \n",
    "    @property\n",
    "    def label_prob(self):\n",
    "        return self.__label_prob\n",
    "    \n",
    "    @property\n",
    "    def total_word_count(self):\n",
    "        return self.__total_word_count\n",
    "\n",
    "    def predict(self,abstract:str):\n",
    "        word_amount=len(self.word_weight)\n",
    "        word_list=abstract.split()\n",
    "        propbability=list(self.label_prob)\n",
    "        for w in word_list:\n",
    "            if w in self.word_weight:\n",
    "                index=0\n",
    "                while index<4:\n",
    "                    smooth_prob=(sum(self.word_weight[w])-self.word_weight[w][index]+1)/(sum(self.total_word_count)-self.total_word_count[index]+word_amount)\n",
    "                    propbability[index]-=math.log(smooth_prob)\n",
    "                    index+=1\n",
    "        max_index=[index for index,item in enumerate(propbability) if item==max(propbability)]\n",
    "        return possible_label[choice(max_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and ten fold cross validation method for Complement Naive Bayes algorithm\n",
    "def train_complement_naive_Bayesian(dataset):\n",
    "    word_dict=dict()\n",
    "    total_word_count=[0,0,0,0]\n",
    "    label_count=[0,0,0,0]\n",
    "    for D in dataset:\n",
    "        analyze_abstract(word_dict,total_word_count,D[0],D[1])\n",
    "        label_count[possible_label.index(D[1])]+=1\n",
    "    return ComplementBayesainModel(word_dict,[math.log(x/len(dataset)) if x!=0 else 0 for x in label_count],total_word_count)\n",
    "\n",
    "def ten_fold_cross_validate_CNB(data):\n",
    "    folds=[[],[],[],[],[],[],[],[],[],[]]\n",
    "    data=list(data)\n",
    "    while len(data)>0:\n",
    "        fold_slot=list(range(10))\n",
    "        while len(fold_slot)>0 and len(data)>0:\n",
    "            seed()\n",
    "            example=data.pop(randint(0,len(data)-1))\n",
    "            slot=fold_slot.pop(randint(0,len(fold_slot)-1))\n",
    "            folds[slot].append(example)\n",
    "    accuracy_list=[]\n",
    "    for i in range(10):\n",
    "        valid_fold=folds[i]\n",
    "        train_fold=[]\n",
    "        for f in folds:\n",
    "            if f!=valid_fold:\n",
    "                train_fold+=f\n",
    "        model=train_complement_naive_Bayesian(train_fold)\n",
    "        evaluation=evaluate(model,valid_fold)\n",
    "        accuracy_list.append(evaluation[2])\n",
    "    return accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of ten fold cross validation is as follows:\n",
      "[0.9901315789473685, 0.9901315789473685, 0.9901315789473685, 0.9835526315789473, 0.9769736842105263, 0.9802631578947368, 0.9802631578947368, 0.9901315789473685, 0.9703947368421053, 0.993421052631579]\n",
      "The Complement Naive Bayes algorithm with oversmapling minority class has an average validation accuracy of 0.9845394736842106\n",
      "\n",
      "The accuray of the Complement Naive Bayes algorithm with oversmapling minority class is 0.9625\n",
      "The accuracy of the Complement Naive Bayes algorithm with oversmapling minority class for each classes are:\n",
      "              A       B       E     V\n",
      "success   16.00  330.00  403.00  21.0\n",
      "fail       5.00   22.00    3.00   0.0\n",
      "accuracy   0.76    0.94    0.99   1.0\n",
      "\n",
      "The result of 20 test with random dataset of the model is as follows:\n",
      "[0.95875, 0.94625, 0.96125, 0.9475, 0.945, 0.955, 0.95, 0.94875, 0.96625, 0.95125, 0.96375, 0.9425, 0.95625, 0.94875, 0.95375, 0.95875, 0.95375, 0.9425, 0.95625, 0.95625]\n",
      "The accuracy of  Complement Naive Bayes algorithm with oversmapling minority class is 0.9531250000000002\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap training set\n",
    "train_data=[]\n",
    "while len(train_data)<1600:\n",
    "    train_data.append(choice(trainset))\n",
    "# Oversample minority class\n",
    "majority=len([d for d in train_data if d[1]==\"B\" or d[1]==\"E\"])\n",
    "oversample_minority=math.floor(majority/2)\n",
    "ros=RandomOverSampler(random_state=100, sampling_strategy={\"A\":oversample_minority,\"V\":oversample_minority})\n",
    "train_data=ros.fit_resample(train_data,[d[1] for d in train_data])[0]\n",
    "\n",
    "ten_fold_accuracy_NB_FS=ten_fold_cross_validate_CNB(train_data)\n",
    "print(\"The result of ten fold cross validation is as follows:\")\n",
    "print(ten_fold_accuracy_NB_FS)\n",
    "print(f\"The Complement Naive Bayes algorithm with oversmapling minority class has an average validation accuracy of {sum(ten_fold_accuracy_NB_FS)/10}\\n\")\n",
    "\n",
    "CNB_model=train_complement_naive_Bayesian(train_data)\n",
    "\n",
    "success,fail,accuracy,total_accuracy=detail_evaluation(CNB_model,test_data)\n",
    "print(f\"The accuray of the Complement Naive Bayes algorithm with oversmapling minority class is {total_accuracy}\")\n",
    "print(\"The accuracy of the Complement Naive Bayes algorithm with oversmapling minority class for each classes are:\")\n",
    "print(pd.DataFrame([success,fail,accuracy],index=[\"success\",\"fail\",\"accuracy\"],columns=possible_label))\n",
    "\n",
    "oversample_CNB=get_test_accuracy_model(CNB_model,20)\n",
    "print(\"\\nThe result of 20 test with random dataset of the model is as follows:\")\n",
    "print(oversample_CNB)\n",
    "print(f\"The accuracy of  Complement Naive Bayes algorithm with oversmapling minority class is {sum(oversample_CNB)/20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Least 91% confident level, there is a statistical significant difference between the accuracy of standard Naive Bayes algorithm\n",
      "and Complementary Naive Bayes algorithem with oversample minority class on the test dataset\n",
      "\n",
      "At Least 86% confident level, there is a statistical significant difference between the accuracy of standard Naive Bayes algorithm\n",
      "with oversample minority class and Complementary Naive Bayes algorithem with oversample minority class on the test dataset\n"
     ]
    }
   ],
   "source": [
    "stats,pvalue =ttest_ind(standard_Bayesian,oversample_Bayesian)\n",
    "siglvl=math.ceil(100-abs(stats*2))\n",
    "print(f\"At Least {siglvl}% confident level, there is a statistical significant difference between the accuracy of standard Naive Bayes algorithm\")\n",
    "print(\"and Complementary Naive Bayes algorithem with oversample minority class on the test dataset\\n\")\n",
    "stats,pvalue =ttest_ind(oversample_Bayesian,oversample_CNB)\n",
    "siglvl=math.ceil(100-abs(stats*2))\n",
    "print(f\"At Least {siglvl}% confident level, there is a statistical significant difference between the accuracy of standard Naive Bayes algorithm\")\n",
    "print(\"with oversample minority class and Complementary Naive Bayes algorithem with oversample minority class on the test dataset\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Part 3**: Train and Test to submit Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap training datas\n",
    "seed(100)\n",
    "train_data=[]\n",
    "while len(train_data)<len(dataset):\n",
    "    train_data.append(choice(dataset))\n",
    "# Oversample minority class with Iblearn\n",
    "majority=len([d for d in train_data if d[1]==\"B\" or d[1]==\"E\"])\n",
    "oversample_minority=math.floor(majority/2)\n",
    "ros=RandomOverSampler(random_state=100, sampling_strategy={\"A\":oversample_minority,\"V\":oversample_minority})\n",
    "train_data=ros.fit_resample(train_data,[d[1] for d in train_data])[0]\n",
    "# Train a Complement Naive Bayesian model (see Part 2.2) with training Data \n",
    "Submission_model=train_complement_naive_Bayesian(train_data)\n",
    "# Read tst.csv file and record predicted classes with the model\n",
    "Predictset=[]\n",
    "file=open(\"tst.csv\")\n",
    "test_csv=csv.DictReader(file)\n",
    "for row in test_csv:\n",
    "   abstract=row[\"abstract\"]\n",
    "   Predictset.append([row[\"id\"],Submission_model.predict(abstract)])\n",
    "file.close()\n",
    "# Write all predictions model to Predict.csv file\n",
    "file=open(\"Predict.csv\",\"w\")\n",
    "file.writelines(\"id,class\\n\")\n",
    "for p in Predictset:\n",
    "    file.writelines(str.join(\",\",p)+\"\\n\")\n",
    "file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
